{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State space: Box(4,)\n",
      "- low: [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
      "- high: [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "Actions space: Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0') #MsPacman-v0\n",
    "# Explore state (observation) space\n",
    "print(\"State space:\", env.observation_space)\n",
    "print(\"- low:\", env.observation_space.low)\n",
    "print(\"- high:\", env.observation_space.high)\n",
    "print(\"Actions space:\", env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uniform_grid(low, high, bins=(10, 10)):\n",
    "    \"\"\"Define a uniformly-spaced grid that can be used to discretize a space.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    low : array_like\n",
    "        Lower bounds for each dimension of the continuous space.\n",
    "    high : array_like\n",
    "        Upper bounds for each dimension of the continuous space.\n",
    "    bins : tuple\n",
    "        Number of bins along each corresponding dimension.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    grid : list of array_like\n",
    "        A list of arrays containing split points for each dimension.\n",
    "    \"\"\"\n",
    "    return [np.linspace(low[i], high[i], num=(bins[i]+1))[1:-1] for i in range(len(low))]\n",
    "\n",
    "def discretize(sample, grid):\n",
    "    \"\"\"Discretize a sample as per given grid.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sample : array_like\n",
    "        A single sample from the (original) continuous space.\n",
    "    grid : list of array_like\n",
    "        A list of arrays containing split points for each dimension.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    discretized_sample : array_like\n",
    "        A sequence of integers with the same number of dimensions as sample.\n",
    "    \"\"\"\n",
    "    # TODO: Implement this\n",
    "    return [np.digitize(sample[i], grid[i]) for i in range(len(grid)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GymAgent:\n",
    "\n",
    "    def __init__(self, nS=(210, 160, 3), nA=9, state_grid=None, gamma=0.9, alpha=0.1, eps=0.9):\n",
    "        \"\"\" Initialize agent.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "        - nA: number of actions available to the agent\n",
    "        \"\"\"\n",
    "        self.nA = nA\n",
    "        self.state_grid = state_grid\n",
    "        self.gamma = gamma\n",
    "        self.alpha = 0.1\n",
    "        self.eps = eps\n",
    "        self.Q = defaultdict(lambda: np.zeros(self.nA))\n",
    "        \n",
    "    def convertState(self, state):\n",
    "        return tuple(np.array(discretize(state, self.state_grid)))\n",
    "    \n",
    "    def getExpectedValue(self, state):\n",
    "        sk = self.convertState(state)\n",
    "        #sk = str(tuple(current_state.flatten())).replace(', ','')\n",
    "        ev = (1-self.eps)*np.argmax(self.Q[sk])+(self.eps/self.nA)*sum([self.Q[sk][ai] for ai in range(self.nA)])\n",
    "        return ev\n",
    "\n",
    "    def select_action(self, state, mode='train'):\n",
    "        \"\"\" Given the state, select an action.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "        - state: the current state of the environment\n",
    "\n",
    "        Returns\n",
    "        =======\n",
    "        - action: an integer, compatible with the task's action space\n",
    "        \"\"\"\n",
    "        sk = self.convertState(state)\n",
    "        \n",
    "        if mode == 'train' and np.random.rand() < self.eps:\n",
    "            a = np.random.choice(self.nA)\n",
    "        else:\n",
    "            a = np.argmax(self.Q[sk])\n",
    "        \n",
    "        return a\n",
    "\n",
    "    def update_Q(self, state, action, reward, next_state, done):\n",
    "        \"\"\" Update the agent's knowledge, using the most recently sampled tuple.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "        - state: the previous state of the environment\n",
    "        - action: the agent's previous choice of action\n",
    "        - reward: last reward received\n",
    "        - next_state: the current state of the environment\n",
    "        - done: whether the episode is complete (True or False)\n",
    "        \"\"\"\n",
    "        sk = self.convertState(state)\n",
    "        #sk = str(tuple(current_state.flatten())).replace(', ','')\n",
    "        target_value = reward + self.gamma*self.getExpectedValue(next_state)\n",
    "        current_value = self.Q[sk][action]\n",
    "        self.Q[sk][action] += self.alpha*(target_value - current_value)\n",
    "        \n",
    "    def run(self, env, num_episodes=100, mode='train'):\n",
    "        average_score = []\n",
    "        tmp_score_hist = []\n",
    "        for t in range(num_episodes):\n",
    "            score = 0\n",
    "            init_state = env.reset()\n",
    "            current_state = init_state\n",
    "            while True:\n",
    "                #action = env.action_space.sample()\n",
    "                action = self.select_action(current_state, mode)\n",
    "                \n",
    "                if mode=='test':\n",
    "                    env.render()\n",
    "\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                if mode=='train':\n",
    "                    self.update_Q(current_state, action, reward, next_state, done)\n",
    "                score += reward\n",
    "                if done:\n",
    "                    tmp_score_hist.append(score)\n",
    "                    break\n",
    "                else:\n",
    "                    current_state = next_state\n",
    "            #end of while loop\n",
    "\n",
    "            if t%(num_episodes/10) == 0: #decay eps\n",
    "                gym_agent.eps = max(gym_agent.eps*0.95,0.1)\n",
    "                \n",
    "            if t%100 == 0:\n",
    "                avg_score = sum(tmp_score_hist)/len(tmp_score_hist)\n",
    "                tmp_score_hist = []\n",
    "                average_score.append(avg_score)\n",
    "                print(\"\\rEpisode {}/{}. Score: {}. Qtable size: {}. eps: {}.   \".format(t, num_episodes, \n",
    "                                                                                        avg_score, \n",
    "                                                                                        len(gym_agent.Q),\n",
    "                                                                                        gym_agent.eps), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "            #end of one episode\n",
    "        return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = tuple([80 for i in range(len(env.observation_space.high))])\n",
    "state_grid = create_uniform_grid(env.observation_space.low, env.observation_space.high, bins=bins)\n",
    "gym_agent = GymAgent(env.observation_space.shape, env.action_space.n, state_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 303500/5000000. Score: 23.7. Qtable size: 3812. eps: 0.855.    "
     ]
    }
   ],
   "source": [
    "average_score = gym_agent.run(env, 5000000, mode='train')       \n",
    "plt.plot(average_score)\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Episode 0/2. Score: 28.0. Qtable size: 1342. eps: 0.5119200830488138.   "
     ]
    }
   ],
   "source": [
    "average_score = gym_agent.run(env, 2, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
