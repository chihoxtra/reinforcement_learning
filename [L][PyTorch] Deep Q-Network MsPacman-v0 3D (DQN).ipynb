{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem statement:\n",
    "https://gym.openai.com/envs/MsPacman-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvirtualdisplay in /Users/samuelpun_old/anaconda3/lib/python3.6/site-packages (0.2.1)\n",
      "Requirement already satisfied: EasyProcess in /Users/samuelpun_old/anaconda3/lib/python3.6/site-packages (from pyvirtualdisplay) (0.2.5)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gym\n",
    "#!pip3 install box2d\n",
    "import random\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from dqn_agent_3d import Agent\n",
    "\n",
    "!python -m pip install pyvirtualdisplay\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape:  (210, 160, 3)\n",
      "Number of actions:  9\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MsPacman-v0')\n",
    "env.seed(0)\n",
    "state_space = env.observation_space.shape\n",
    "action_space = env.action_space.n\n",
    "input_shape = (84,84)\n",
    "states_stack_depth = 4\n",
    "print('State shape: ', state_space)\n",
    "print('Number of actions: ', action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For inputs basic pre-processing\n",
    "encode_states = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(input_shape),\n",
    "    transforms.ToTensor()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 84, 84])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import images\n",
    "s = env.reset()\n",
    "encode_states(s).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "untrained_agent = Agent(state_size=states_stack_depth, action_size=action_space, seed=10)\n",
    "\n",
    "# watch an untrained agent\n",
    "states_stack = deque([torch.zeros(input_shape) for z in range(states_stack_depth)], maxlen=states_stack_depth)\n",
    "\n",
    "state = env.reset()\n",
    "state_inputs = state2StackedInputs(state, states_stack)\n",
    "\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "for j in range(1000):\n",
    "    action = untrained_agent.act(state_inputs)\n",
    "    img.set_data(env.render(mode='rgb_array')) \n",
    "    plt.axis('off')\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break \n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=states_stack_depth, action_size=action_space, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state2StackedInputs(s, states_stack):\n",
    "    encoded_state = encode_states(s) #210x160x3 -> 1x84x84\n",
    "    \n",
    "    #combine the max element between this frame and last frame  \n",
    "    merged_next_state = torch.stack((encoded_state.squeeze(),states_stack[-1]), dim=0).max(dim=0)[0]\n",
    "    states_stack.append(merged_next_state) #last in the stack and first is out hence\n",
    "\n",
    "    #convert to tensor for input\n",
    "    state_inputs = torch.stack([states_stack[i] for i in range(len(states_stack))]).numpy()\n",
    "    return state_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10\tAverage Score: 223.00"
     ]
    }
   ],
   "source": [
    "model_dir = 'saved_models/'\n",
    "model_name = 'MsPacman-3D-v0.pt'\n",
    "\n",
    "def dqn_3D(n_episodes=1000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.9995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    \n",
    "    #stack to keep track of most recent states\n",
    "    states_stack = deque([torch.zeros(input_shape) for z in range(states_stack_depth)], maxlen=states_stack_depth)\n",
    "    \n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        \n",
    "        state = env.reset()\n",
    "        \n",
    "        state_inputs = state2StackedInputs(state, states_stack)\n",
    "\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "\n",
    "            action = agent.act(state_inputs, eps) #for action recommendation\n",
    "            \n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            next_state_inputs = state_inputs = state2StackedInputs(next_state, states_stack)\n",
    "            \n",
    "            np.expand_dims(state_inputs,0)\n",
    "            \n",
    "            agent.step(state_inputs , action, reward, next_state_inputs, done)\n",
    "\n",
    "            state_inputs = next_state_inputs\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}\\teps: {:.2f}'.format(i_episode, np.mean(scores_window), eps))\n",
    "        \n",
    "        if np.mean(scores_window)>=1000.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100,\n",
    "                                                                                         np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), model_dir+model_name)\n",
    "            break\n",
    "        \n",
    "    return scores\n",
    "\n",
    "scores = dqn_3D(20)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_dir = 'saved_models/'\n",
    "model_name = 'MsPacman-3D-v0.pt'\n",
    "\n",
    "# after training, save your model parameters in the dir 'saved_models'\n",
    "torch.save(agent.qnetwork_local.state_dict(), model_dir+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the weights from file\n",
    "#torch.load(agent.qnetwork_local.state_dict(), model_dir+model_name)\n",
    "\n",
    "for i in range(3):\n",
    "    # watch an untrained agent\n",
    "    states_stack = deque([torch.zeros(input_shape) for z in range(states_stack_depth)], maxlen=states_stack_depth)\n",
    "\n",
    "    state = env.reset()\n",
    "    state_inputs = state2StackedInputs(state, states_stack)\n",
    "    img = plt.imshow(env.render(mode='rgb_array'))\n",
    "    for j in range(1000):\n",
    "        action = agent.act(state_inputs)\n",
    "        img.set_data(env.render(mode='rgb_array')) \n",
    "        plt.axis('off')\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break \n",
    "            \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
